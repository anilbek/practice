{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154c64b-c66e-4e6a-b47c-2327d1bfdd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# %%\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "EXPERIMENT_NAME = \"dl_model_chapter07\"\n",
    "mlflow.set_tracking_uri('http://localhost')\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "print(\"experiment_id:\", experiment.experiment_id)\n",
    "\n",
    "\n",
    "# %%\n",
    "class InferencePipeline(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        self.finetuned_model = mlflow.sklearn.load_model(self.finetuned_model_uri)\n",
    "    \n",
    "    def __init__(self, finetuned_model_uri):\n",
    "        self.finetuned_model_uri = finetuned_model_uri\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        results = self.finetuned_model.predict(model_input)\n",
    "        return results\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "CONDA_ENV = os.path.join(Path(os.path.dirname(os.path.abspath(__file__))).parent, \"conda.yaml\")\n",
    "print(CONDA_ENV)\n",
    "\n",
    "# %%\n",
    "MODEL_ARTIFACT_PATH = 'inference_pipeline_model'\n",
    "with mlflow.start_run(run_name=\"inference_pipeline\") as model_tracking_run:\n",
    "    \n",
    "    # replace the run id for a new project\n",
    "    finetuned_model_uri = 'runs:/1290f813d8e74a249c86eeab9f6ed24e/model'\n",
    "    inference_pipeline_uri = f'runs:/{model_tracking_run.info.run_id}/{MODEL_ARTIFACT_PATH}'\n",
    "    mlflow.pyfunc.log_model(artifact_path=MODEL_ARTIFACT_PATH, \n",
    "                            conda_env=CONDA_ENV, \n",
    "                            python_model=InferencePipeline(finetuned_model_uri))     \n",
    "\n",
    "\n",
    "# %%\n",
    "df=pd.read_csv(\"data/training/data.csv\")\n",
    "\n",
    "# %%\n",
    "with mlflow.start_run(run_name=\"run_inference_pipeline\") as model_prediction_run:\n",
    "    loaded_model = mlflow.pyfunc.load_model(inference_pipeline_uri)\n",
    "    results = loaded_model.predict(df)\n",
    "\n",
    "\n",
    "# %%\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
