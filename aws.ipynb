{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf060af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "region = boto3.session.Session().region_name\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8331d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0', role=role, instance_type='ml.t3.medium', instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312a54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_data = 's3://steelrawdata/faults.csv'\n",
    "df = pd.read_csv(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1c5b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train-test-split-ratio', type=float, default=0.2)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    print('Received arguments {}'.format(args))\n",
    "    input_data_path = os.path.join('/opt/ml/processing/input', 'faults.csv')\n",
    "    print('Reading input data from {}'.format(input_data_path))\n",
    "    df = pd.read_csv(input_data_path)\n",
    "    \n",
    "    label_list=df.columns.values[-7:]\n",
    "    \n",
    "    features_list=[]\n",
    "    for i, column in enumerate(df.columns.values):\n",
    "        if column not in label_list:\n",
    "            features_list.append(column)\n",
    "    \n",
    "    categorical_features = [] + label_list.tolist()\n",
    "    for feature in features_list:\n",
    "        for char in feature:\n",
    "            if char.isdigit():\n",
    "                if feature not in categorical_features:\n",
    "                    categorical_features.append(feature)\n",
    "    \n",
    "    numerical_features = []\n",
    "    for feature in features_list:\n",
    "        if feature not in categorical_features:\n",
    "            numerical_features.append(feature)\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    df[numerical_features] = ss.fit_transform(df[numerical_features])\n",
    "    \n",
    "    split_ratio = args.train_test_split_ratio\n",
    "    print('Splitting data into train and test sets with ratio {}'.format(split_ratio))\n",
    "    \n",
    "    df['Pastry'].replace({1: 'Pastry', 0: ''}, inplace = True)\n",
    "    df['Z_Scratch'].replace({1: 'Z_Scratch', 0: ''}, inplace = True)\n",
    "    df['K_Scatch'].replace({1: 'K_Scatch', 0: ''}, inplace = True)\n",
    "    df['Stains'].replace({1: 'Stains', 0: ''}, inplace = True)\n",
    "    df['Dirtiness'].replace({1: 'Dirtiness', 0: ''}, inplace = True)\n",
    "    df['Bumps'].replace({1: 'Bumps', 0: ''}, inplace = True)\n",
    "    df['Other_Faults'].replace({1: 'Other_Faults', 0: ''}, inplace = True)\n",
    "    df['targets']= wdf_1['Pastry'] + wdf_1['Z_Scratch'] + wdf_1['K_Scatch'] + wdf_1['Stains'] + wdf_1['Dirtiness'] + wdf_1['Bumps'] + wdf_1['Other_Faults']\n",
    "    df.drop(columns = label_list, inplace = True)\n",
    "    df = pd.concat([df['targets'], df.drop(['targets'], axis=1)], axis=1)\n",
    "    \n",
    "    X = df[features_list].values\n",
    "    y = df['targets'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio, random_state=1, shuffle=True, stratify=y)\n",
    "    \n",
    "    train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_features.csv')\n",
    "    train_labels_output_path = os.path.join('/opt/ml/processing/train', 'train_labels.csv')\n",
    "    test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_features.csv')\n",
    "    test_labels_output_path = os.path.join('/opt/ml/processing/test', 'test_labels.csv')\n",
    "    print('Saving training features to {}'.format(train_features_output_path))\n",
    "    pd.DataFrame(X_train).to_csv(train_features_output_path, header=False,index=False)\n",
    "    print('Saving test features to {}'.format(test_features_output_path))\n",
    "    pd.DataFrame(X_test).to_csv(test_features_output_path, header=False, index=False)\n",
    "    print('Saving training labels to {}'.format(train_labels_output_path))\n",
    "    y_train.to_csv(train_labels_output_path, header=False, index=False)\n",
    "    print('Saving test labels to {}'.format(test_labels_output_path))\n",
    "    y_test.to_csv(test_labels_output_path, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "            inputs=[ProcessingInput(source=input_data, destination='/opt/ml/processing/input')], \n",
    "            outputs=[ProcessingOutput(output_name='train_data', source='/opt/ml/processing/train',destination='s3://steelrawdata/train/'),\n",
    "                     ProcessingOutput(output_name='test_data', source='/opt/ml/processing/test', destination='s3://steelrawdata/test/')],\n",
    "            arguments=['--train-test-split-ratio', '0.2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    print(output['S3Output']['S3Uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_role = 'arn:aws:iam::322704388865:role/practice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abdfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training.py\n",
    "\n",
    "import os, argparse\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(os.path.join(model_dir, 'xgb.model'))\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--num_round', type=int, default=50)\n",
    "    parser.add_argument('--max_depth', type=int, default=5)\n",
    "    parser.add_argument('--eta', type=float, default=0.2)\n",
    "    parser.add_argument('--objective', type=str, default='multi:softmax')\n",
    "    parser.add_argument('--early-stopping-rounds', type=int, default=10)\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--training-dir', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "    parser.add_argument('--validation-dir', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    model_dir = args.model_dir\n",
    "    training_dir = args.training_dir\n",
    "    validation_dir = args.validation_dir\n",
    "    chk_dir = '/opt/ml/checkpoints'\n",
    "    \n",
    "    x_train = os.path.join(training_dir, 'train_features.csv')\n",
    "    y_train = os.path.join(training_dir, 'train_labels.csv')\n",
    "    x_test = os.path.join(validation_dir, 'test_features.csv')\n",
    "    y_test = os.path.join(validation_dir, 'test_labels.csv')\n",
    "\n",
    "    train_hp = {\n",
    "        'num_round': args.num_round\n",
    "        'max_depth': args.max_depth,\n",
    "        'eta': args.eta,\n",
    "        'objective': args.objective,\n",
    "        'early_stopping_rounds': args.early_stopping_rounds}\n",
    "    \n",
    "    dtrain = xgb.DMatrix(x_train, label = y_train) # assuming csv will work\n",
    "    dval = xgb.DMatrix(x_test, label = y_test)\n",
    "    watchlist = [(dval,'eval'), (dtrain, 'train')]\n",
    "    \n",
    "    callbacks = [save_checkpoint(chk_dir)]\n",
    "    prev_checkpoint, n_iterations_prev_run = load_checkpoint(chk_dir)\n",
    "    bst = xgb.train(\n",
    "            params=train_hp,\n",
    "            dtrain=dtrain,\n",
    "            evals=watchlist,\n",
    "            num_boost_round=(args.num_round - n_iterations_prev_run),\n",
    "            xgb_model=prev_checkpoint,\n",
    "            callbacks=callbacks) \n",
    "\n",
    "    bst.save_model(os.path.join(model_dir, 'xgb.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for local mode or managed mode\n",
    "enable_local_mode_training = False\n",
    "\n",
    "if enable_local_mode_training:\n",
    "    train_dir = os.path.join(os.getcwd(), \"data/train\")\n",
    "    test_dir = os.path.join(os.getcwd(), \"data/test\")\n",
    "    output_dir = os.path.join(os.getcwd(), \"model/output\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pd.DataFrame(X_train).to_csv(f\"{train_dir}/train_features.csv\", header=False, index=False)\n",
    "    pd.DataFrame(X_test).to_csv(f\"{train_dir}/train_labels.csv\", header=False, index=False)\n",
    "    y_train.to_csv(f\"{test_dir}/test_features.csv\", header=False, index=False)\n",
    "    y_test.to_csv(f\"{test_dir}/test_labels.csv\", header=False, index=False)\n",
    "    \n",
    "    training_path = f\"file://{train_dir}\"\n",
    "    validation_path = f\"file://{test_dir}\"\n",
    "    output_path   = f\"file://{output_dir}\"\n",
    "    train_instance_type = deploy_instance_type = 'local'\n",
    "\n",
    "else:\n",
    "    training_path = \"s3://steelrawdata/train/\"\n",
    "    validation_path = \"s3://steelrawdata/test/\"\n",
    "    output_path   = 's3://steelrawdata/model/'\n",
    "    train_instance_type = deploy_instance_type = 'ml.t3.medium'\n",
    "\n",
    "if this cell doesnt work, do whats done in learn sagemaker book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = TrainingInput(s3_data=training_path, content_type=\"csv\")\n",
    "s3_input_test = TrainingInput(s3_data=validation_path, content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import rule_configs, Rule, CollectionConfig, DebuggerHookConfig\n",
    "\n",
    "rules = [Rule.sagemaker(\n",
    "            base_config=rule_configs.overfit(),\n",
    "            rule_parameters={\"patience\": \"10\",\n",
    "                             \"ratio_threshold\": \"0.1\"},\n",
    "            collections_to_save=[\n",
    "                CollectionConfig(name=\"losses\", \n",
    "                                 parameters={\"train.save_interval\": \"5\", \n",
    "                                             \"eval.save_interval\": \"5\"})]),\n",
    "        Rule.sagemaker(\n",
    "            base_config=rule_configs.overtraining(),\n",
    "            rule_parameters={\"patience_train\": \"5\",\n",
    "                             \"patience_validation\": \"10\",\n",
    "                             \"delta\": \"0.01\"},\n",
    "            collections_to_save=[\n",
    "                CollectionConfig(name=\"losses\", \n",
    "                                 parameters={\"save_interval\": \"5\"})])\n",
    "        Rule.sagemaker(\n",
    "            base_config=rule_configs.loss_not_decreasing(),\n",
    "            rule_parameters={\n",
    "                \"collection_names\": \"losses\"\n",
    "                \"use_losses_collection\": \"True\",\n",
    "                \"num_steps\": \"10\",\n",
    "                \"diff_percent\": \"0.1\",\n",
    "                \"increase_threshold_percent\": \"5\",},\n",
    "            collections_to_save=[ \n",
    "                CollectionConfig(name=\"losses\", \n",
    "                                 parameters={\"save_interval\": \"5\"})])]\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(s3_output_path='s3://steelrawdata/debug',\n",
    "                                          collection_configs=[CollectionConfig(name='metrics',\n",
    "                                                                               parameters={\"save_interval\":'2'}),\n",
    "                                                              CollectionConfig(name='average_shap', \n",
    "                                                                               parameters={\"save_interval\":'2'}),\n",
    "                                                              CollectionConfig(name='feature_importance',\n",
    "                                                                               parameters={\"save_interval\": '2'})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13eb994",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_spot_instances = True\n",
    "max_run = 60\n",
    "max_wait = 60 if use_spot_instances else None\n",
    "chkp_path = (\"s3://steelrawdata/checkpoints/\" if use_spot_instances else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point='training.py', \n",
    "    role=new_role #sagemaker.get_execution_role(),\n",
    "    instance_count=1, \n",
    "    instance_type=train_instance_type,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    checkpoint_s3_uri=chkp_path\n",
    "    framework_version='1.2-2',\n",
    "    output_path=\"s3://steelrawdata/model/\",\n",
    "    hyperparameters={'num_round': 100, 'num_class': 7}, # check if this will override the default value\n",
    "    rules = rules,\n",
    "    debugger_hook_config=debugger_hook_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbe2fd9",
   "metadata": {},
   "source": [
    "### hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ca2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation:accuracy'\n",
    "objective_type = 'Maximize'\n",
    "metric_definitions = [\n",
    "    {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ca260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0.1, 0.5),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2, scaling_type=\"Logarithmic\"), \n",
    "    \"max_depth\": IntegerParameter(1, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "tuner = HyperparameterTuner(xgb_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            objective_type=objective_type,\n",
    "                            strategy='Random'\n",
    "                            max_jobs=30,\n",
    "                            max_parallel_jobs=2,\n",
    "                            early_stopping_type='Auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b87021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ce8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({\"train\": s3_input_train, \"validation\": s3_input_test})\n",
    "training_job_description = sklearn.jobs[-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee57017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for a couple of jobs to start\n",
    "\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "hp_results = HyperparameterTuningJobAnalytics(\n",
    "  hyperparameter_tuning_job_name=tuner.latest_tuning_job.name)\n",
    "\n",
    "hp_results = exp.dataframe()\n",
    "\n",
    "jobs.sort_values('FinalObjectiveValue', ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = tuner.latest_training_job.rule_job_summary() # if tuner doesnt work, try xgb_estimator\n",
    "\n",
    "for rule in description:\n",
    "    rule.pop('LastModifiedTime')\n",
    "    rule.pop('RuleEvaluationJobArn')\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ec025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "trial = create_trial(tuner.latest_job_debugger_artifacts_path())\n",
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55107c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "steps = trial.tensor(\"train-acc\").steps()\n",
    "train_acc = [trial.tensor('train-acc').value(s) for s in steps]\n",
    "val_acc = [trial.tensor('validation-acc').value(s) for s in steps]\n",
    "\n",
    "plt.title('acc over steps')\n",
    "plt.autoscale()\n",
    "plt.plot(steps, train_acc, label='train', color='black')\n",
    "plt.plot(steps, val_acc, label='val', color='grey')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef722bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(tensor_prefix):\n",
    "    num_features = len(df.columns)-1\n",
    "    for i in range(0,num_features):\n",
    "        f_name = tensor_prefix+'/f'+str(i)\n",
    "        steps = trial.tensor(f_name).steps()\n",
    "        v = [trial.tensor(f_name).value(s) for s in steps]\n",
    "        plt.plot(steps, v, label=dataset.columns[i+1])\n",
    "    plt.autoscale()\n",
    "    plt.title(tensor_prefix)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features('average_shap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features('feature_importance/weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime,gmtime\n",
    "from sagemaker.model_monitor.data_capture_config import DataCaptureConfig\n",
    "\n",
    "xgb_endpoint_name = 'xgboost-steel'+strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "capture_path = 's3://steelrawdata/capture/'\n",
    "\n",
    "xgb_predictor = tuner.deploy(\n",
    "    endpoint_name=xgb_endpoint_name,\n",
    "    initial_instance_count=1, \n",
    "    instance_type=deploy_instance_type\n",
    "    data_capture_config=DataCaptureConfig(       \n",
    "        enable_capture=True,                     # Capture data\n",
    "        sampling_percentage=100,                 \n",
    "        capture_options=['REQUEST', 'RESPONSE'], # Default value\n",
    "        destination_s3_uri=capture_path          # Save data here\n",
    "    )\n",
    ")\n",
    "\n",
    "print(xgb_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca50421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_predictor.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print(precision_score(y_test, predictions, average='weighted'))\n",
    "print(recall_score(y_test, predictions, average='weighted'))\n",
    "print(f1_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd0fd6",
   "metadata": {},
   "source": [
    "### monitoring predicton quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_train, y_train)], axis = 1)\n",
    "data.to_csv('baseline_data.csv',index=False)\n",
    "baseline_data = sess.upload_data(path = 'baseline_data.csv', bucket = 's3://steelrawdata/model-monitor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "xgb_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1, \n",
    "    instance_type='ml.t3.medium'\n",
    ")\n",
    "\n",
    "baseline_path = 's3://steelrawdata/model-monitor/'\n",
    "\n",
    "xgb_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7602809",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = xgb_monitor.latest_baselining_job\n",
    "\n",
    "schema = pd.io.json.json_normalize(baseline_results.baseline_statistics().body_dict[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = pd.io.json.json_normalize(baseline_results.suggested_constraints().body_dict[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631a6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "xgb_monitor_name = prefix+'-mon-'+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "report_path = 's3://steelrawdata/report'\n",
    "\n",
    "xgb_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=xgb_monitor_name,\n",
    "    endpoint_input=xgb_predictor.endpoint_name,\n",
    "    output_s3_uri=report_path,\n",
    "    statistics=xgb_monitor.baseline_statistics(),\n",
    "    constraints=xgb_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = xgb_monitor.latest_monitoring_constraint_violations()\n",
    "violations = pd.io.json.json_normalize(violations.body_dict[\"violations\"])\n",
    "violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a481079",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390af27a",
   "metadata": {},
   "source": [
    "### canary rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_1 = 'xgb'\n",
    "model_name_2 = 'xgb_updated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3def39",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_variants = [\n",
    "        {\n",
    "            'VariantName': 'variant-1',\n",
    "            'ModelName': model_name_1,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InitialVariantWeight': 9,\n",
    "            'InstanceType': 'ml.t3.medium'\n",
    "        },\n",
    "        {\n",
    "            'VariantName': 'variant-2',\n",
    "            'ModelName': model_name_2,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InitialVariantWeight': 1,\n",
    "            'InstanceType': 'ml.t3.medium'\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c39824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "endpoint_config_name = 'xgboost-two-models-epc-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4327bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config = sm.create_endpoint_config(\n",
    "    EndpointConfigName='my_endpoint_config_name',\n",
    "    ProductionVariants=production_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.update_endpoint(\n",
    "    EndpointName='my_endpoint_name',\n",
    "    EndpointConfigName=my_endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b181c7",
   "metadata": {},
   "source": [
    "### blue/green deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7253fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the new model performs well:\n",
    "\n",
    "updated_endpoint_config=[\n",
    "    {\n",
    "     'VariantName': 'variant-1',\n",
    "     'ModelName': model_name_1,\n",
    "     'InstanceType':'ml.m3.medium',\n",
    "     'InitialInstanceCount': 1,\n",
    "     'InitialVariantWeight': 0,\n",
    "    },\n",
    "    {\n",
    "     'VariantName': 'variant-2',\n",
    "     'ModelName': 'ModelB',\n",
    "     'InstanceType':model_name_2,\n",
    "     'InitialInstanceCount': 1,\n",
    "     'InitialVariantWeight': 1,\n",
    "    }\n",
    "]\n",
    "sm.update_endpoint_weights_and_capacities(\n",
    "    EndpointName='my_endpoint_name',\n",
    "    DesiredWeightsAndCapacities=updated_endpoint_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_endpoint_config=[\n",
    "    {\n",
    "     'VariantName': 'variant-2',\n",
    "     'ModelName': model_name_2,\n",
    "     'InstanceType':'ml.m3.medium',\n",
    "     'InitialInstanceCount': 1,\n",
    "     'InitialVariantWeight': 1,\n",
    "    }\n",
    "]\n",
    "\n",
    "sm.update_endpoint(\n",
    "    EndpointName='my_endpoint_name',\n",
    "    EndpointConfigName='my_endpoint_config_name'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2aae8",
   "metadata": {},
   "source": [
    "### A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_endpoint_config=[\n",
    "    {\n",
    "     'VariantName': 'variant-1',\n",
    "     'ModelName': model_name_1,\n",
    "     'InstanceType':'ml.m3.medium',\n",
    "     'InitialInstanceCount': 1,\n",
    "     'InitialVariantWeight': 50,\n",
    "    },\n",
    "    {\n",
    "     'VariantName': 'variant-2',\n",
    "     'ModelName': 'ModelB',\n",
    "     'InstanceType':model_name_2,\n",
    "     'InitialInstanceCount': 1,\n",
    "     'InitialVariantWeight': 50,\n",
    "    }\n",
    "]\n",
    "sm.update_endpoint_weights_and_capacities(\n",
    "    EndpointName='my_endpoint_name',\n",
    "    DesiredWeightsAndCapacities=updated_endpoint_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87299740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming monitored performance for variant B after weeks is better\n",
    "\n",
    "updated_endpoint_config=[\n",
    "    {\n",
    "     'VariantName': 'variant-2',\n",
    "     'ModelName': 'ModelB',\n",
    "     'InstanceType':model_name_2,\n",
    "     'InitialInstanceCount': 1,\n",
    "     'InitialVariantWeight': 1,\n",
    "    }\n",
    "]\n",
    "\n",
    "sm.update_endpoint(\n",
    "    EndpointName='my_endpoint_name',\n",
    "    EndpointConfigName='my_endpoint_config_name'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706d7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b9ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e2e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50875cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
